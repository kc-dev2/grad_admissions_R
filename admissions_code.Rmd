---
title: "Graduate Admissions Prediction"
author: "Kyle Choi"
date: "3/12/2021"
output: html_document
---
***All files related to this project can be found at https://github.com/kc-dev2/grad_admissions_R***

## Purpose

The purpose of this project is to practice exploring and creating models on sample data. More specifically, I have selected graduate admissions data listed on [Kaggle](https://www.kaggle.com/mohansacharya/graduate-admissions). 

While exploring the data, I will ask questions such as "what predictor seems to be most effective in predicting admission probability" and also plot graphs to help communicate/visualize these results. Afterwards, I will create a few linear models to predict admission probabilities and validate these models.

### Exploration

To begin, let us import the data along with necessary libraries:

```{r message=FALSE, results='hide'}
library(tidyverse)
library(ggplot2)
library(corrplot)
library(caret)

adm <- read_csv("../data/admissions.csv")
```

For data "cleaning", I will check to ensure that there are no missing data. Additionally, any columns that need be renamed or have types changed will be fixed.
```{r}
sapply(adm, function(x) sum(is.na(x))) #counting total missing values in each column
str(adm); summary(adm) #checking basic info on data
adm <- rename(adm, GRE = "GRE Score", TOEFL = "TOEFL Score", U_Ranking = "University Rating", adm_chance = "Chance of Admit") #renaming columns

names(adm)
adm$Research <- as.factor(adm$Research) #changing 'Research' column from numerical to factor

str(adm$Research)
```

Let's check potential relationships between predictors and outcome variables. Instead of displaying the correlation plots using plot(), I use the corrplot() function provided by the "corrplot" package to create a visual correlation matrix. Since "Research" column is a factor column, we create a subset of data excluding it to allow for creation of the correlation matrix.
```{r}
sub_adm <- adm[, !names(adm) %in% c("Research")] #remove "Research" column

corrplot(cor(sub_adm), type = "lower", addCoef.col = "black")
```

As displayed in the bottom row (where admission chance is the y-axis for all correlations) we can see that, apart from "Serial No" which is just an ID column, the predictors generally have a strong correlation with admission chance percentages. In particular, a person's Letter of Recommendation (LOR) score has the weakest correlation with admission chances (R=0.65) while his/her undergraduate GPA (CGPA) has the strongest correlation (R=0.88). 

### Modeling

Now, I will go into creating prediction models for our data. Since all variables apart from ID seem to have some correlation with admission chance, I'll first create a linear model that includes all the variables. Then, I'll create another linear model using both ridge and lasso regularization to allow for feature reduction/selection. Finally, I'll create a neural network as part of a more modern ML approach. K-Fold Cross validation (with k=10) will be used to quantify the performance of each model.

Before doing any model creation, let's exclude the "Serial No." column from our dataset:

```{r}
adm_mod <- adm[, !names(adm) %in% c("Serial No.")]
```

Then, let's define the number of folds to be used:
```{r}
training <- trainControl(method="cv", number=10)
```


#### 1. Full Model
We create linear models using the lm() function.

```{r}
set.seed(22) # set seed for reproducible results
full_lm <- train(adm_chance ~ ., data=adm_mod, method="lm", trControl=training)
print(full_lm)
```

This model gives a decent result, with the predictors being able to explain 82% of the variance in the data ($R^{2}$) and having an average error of ~4% ($MAE$).

#### 2. Regularized Model
For regularized models, there are two steps that I take. First, I find the $\lambda$ that optimizes the model, and then test the full model, which now includes the $\lambda$ term, with cross validation. Note that to determine the optimal $\lambda$, another cross validation is required to test out performance of the models against the set of $\lambda$ values.

## Steps to take next

1. Create full model (lm)
~~https://www.geeksforgeeks.org/cross-validation-in-r-programming/~~
https://www.journaldev.com/46754/k-fold-cross-validation-in-r
2. Feature selection model using regularization (lm)
https://towardsdatascience.com/feature-selection-using-regularisation-a3678b71e499
https://uc-r.github.io/regularized_regression
3. Create full model (neural network)
https://www.geeksforgeeks.org/how-neural-networks-are-used-for-regression-in-r-programming/
https://datascienceplus.com/fitting-neural-network-in-r/
4?. Feature selection model using regularization (neural network)
5. Cross validation using k fold to test overall performance of models create in steps 1-4.
https://www.geeksforgeeks.org/cross-validation-in-r-programming/
https://www.statology.org/k-fold-cross-validation-in-r/
6. Select best performing model as prediction model.

Feature importance: https://machinelearningmastery.com/feature-selection-with-the-caret-r-package/

We want to create models that are simpler to avoid overfitting and to also be more cost/time efficient when creating predictions. We can also remove predictors that have collinearity and thus are redundant.